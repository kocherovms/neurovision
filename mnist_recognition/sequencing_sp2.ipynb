{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c8bb0-a8e9-4fec-adc0-8619236e2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEQUENCING SPARE PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034889a8-1439-4433-80e3-28e00f14b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_RECEPTIVE_FIELD_SIZE = 8\n",
    "SENSOR_RECEPTIVE_FIELD_SQUARE = SENSOR_RECEPTIVE_FIELD_SIZE ** 2\n",
    "\n",
    "SENSORS_COUNT = config.sensors_count\n",
    "SENSORS_COUNT_ROOT = int(np.sqrt(SENSORS_COUNT))\n",
    "assert SENSORS_COUNT_ROOT ** 2 == SENSORS_COUNT\n",
    "assert SENSORS_COUNT_ROOT > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de2dd1-932b-4418-8584-8ab6ee1a7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_STATES_INFO = defaultdict(list)\n",
    "SENSOR_STATES_IMG = []\n",
    "sz = SENSOR_RECEPTIVE_FIELD_SIZE\n",
    "captions = []\n",
    "\n",
    "assert config.encoding_type == 'sequence'\n",
    "\n",
    "angle_step = 10 # degrees\n",
    "angles = list(range(0, 360, angle_step)) + [45 * 1, 45 * 3, 45 * 5, 45 * 7]\n",
    "angles = sorted(angles)\n",
    "sweeps = [90, 130, 180, 230, 270] # for receptive field size = 8 more finer sweeps make little sense \n",
    "\n",
    "for angle in angles:\n",
    "    if angle == 0:\n",
    "        # add uber sensor state which will respond to completely illuminated patch\n",
    "        white_canvas = Image.new('L', (sz, sz), color=255)\n",
    "        captions.append(f'ang={angle}, UBER')\n",
    "        SENSOR_STATES_IMG.append(white_canvas)\n",
    "        SENSOR_STATES_INFO['normal'].append(angle)\n",
    "        SENSOR_STATES_INFO['sweep'].append(0)\n",
    "        SENSOR_STATES_INFO['normal_vec'].append(0j)\n",
    "        SENSOR_STATES_INFO['sweep_vec'].append(0j)\n",
    "        SENSOR_STATES_INFO['sweep1_vec'].append(0j)\n",
    "        SENSOR_STATES_INFO['sweep2_vec'].append(0j)\n",
    "    \n",
    "    for sweep in sweeps:\n",
    "        canvas = Image.new('L', (sz, sz))\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "        draw.rectangle([0, 0, sz, sz], fill=127, outline=127)\n",
    "        piesclice_angle1 = angle + sweep // 2\n",
    "        piesclice_angle2 = angle - sweep // 2\n",
    "        draw.pieslice([-sz, -sz, sz * 2 - 1, sz * 2 - 1], start=piesclice_angle1, end=piesclice_angle2, fill=255, outline=255, width=0)\n",
    "        captions.append(f'ang={angle}, swp={sweep} ')\n",
    "        SENSOR_STATES_IMG.append(canvas)\n",
    "        SENSOR_STATES_INFO['normal'].append(angle)\n",
    "        SENSOR_STATES_INFO['sweep'].append(sweep)\n",
    "        SENSOR_STATES_INFO['normal_vec'].append(np.exp((1j) * np.radians(angle)))\n",
    "        SENSOR_STATES_INFO['sweep_vec'].append(np.exp((1j) * np.radians(sweep)))\n",
    "        SENSOR_STATES_INFO['sweep1_vec'].append(np.exp((1j) * np.radians(piesclice_angle1)))\n",
    "        SENSOR_STATES_INFO['sweep2_vec'].append(np.exp((1j) * np.radians(piesclice_angle2)))\n",
    "\n",
    "SENSOR_STATES_INFO = pd.DataFrame(SENSOR_STATES_INFO)\n",
    "assert len(SENSOR_STATES_INFO) == len(SENSOR_STATES_IMG)\n",
    "# n_to_show = len(sweeps) * 4\n",
    "# images_to_show = list(map(lambda x: lay_grid(x.resize((80, 80)), 8), SENSOR_STATES_IMG[:n_to_show]))\n",
    "# display_images_grid(images_to_show, captions=captions[:n_to_show], col_count=len(sweeps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad353d-0575-4260-8f03-1791d3671cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn grayscale images of sensor states to numpy arrays with weights which balance positive and negative areas\n",
    "SENSOR_STATES = np.array(list(map(np.array, SENSOR_STATES_IMG))).astype(float)\n",
    "SENSOR_STATES = SENSOR_STATES.reshape(-1, SENSOR_RECEPTIVE_FIELD_SIZE ** 2)\n",
    "SENSOR_STATES[SENSOR_STATES == 255] = 1\n",
    "SENSOR_STATES[SENSOR_STATES == 127] = -1\n",
    "assert set(np.unique(SENSOR_STATES)) == set([-1, +1])\n",
    "\n",
    "SENSOR_STATES_COUNT = SENSOR_STATES.shape[0]\n",
    "# SENSOR_STATES.shape, np.unique_counts(SENSOR_STATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0366d29-2c22-4f5a-8b6c-401b41b7daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_STATE_AREAS_POS = (SENSOR_STATES == 1).sum(axis=1) \n",
    "SENSOR_STATE_AREAS_NEG = (SENSOR_STATES == -1).sum(axis=1)\n",
    "assert SENSOR_STATE_AREAS_NEG[0] == 0\n",
    "SENSOR_STATE_AREAS_NEG[0] = -1 # UBER sensor state\n",
    "assert np.all(SENSOR_STATE_AREAS_POS > 0)\n",
    "assert np.all(SENSOR_STATE_AREAS_NEG[1:] > 0)\n",
    "# SENSOR_STATE_AREAS_POS.shape, SENSOR_STATE_AREAS_POS.mean(), SENSOR_STATE_AREAS_POS.std(), \\\n",
    "# SENSOR_STATE_AREAS_NEG.shape, SENSOR_STATE_AREAS_NEG.mean(), SENSOR_STATE_AREAS_NEG.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8f0c3-a843-44cd-806c-cef481bbfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_STATES_POS = xp_array_to_gpu_copy(SENSOR_STATES)\n",
    "SENSOR_STATES_NEG = xp_array_to_gpu_copy(SENSOR_STATES)\n",
    "SENSOR_STATES_POS[SENSOR_STATES_POS < 0] = 0\n",
    "SENSOR_STATES_NEG[SENSOR_STATES_NEG > 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c07b07-a2a3-41bd-8a1c-044164a962eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorLayoutMaker(object):\n",
    "    def __call__(self, sensor_index):\n",
    "        return None\n",
    "\n",
    "class SensorLayoutMaker_Grid(SensorLayoutMaker):\n",
    "    def __init__(self):\n",
    "        self.s = SENSORS_COUNT_ROOT\n",
    "        self.field_size = SENSOR_RECEPTIVE_FIELD_SIZE\n",
    "        space_for_sensors = self.s * self.field_size \n",
    "        self.dist_between_sensors = (config.sample_size - space_for_sensors) / (self.s - 1)\n",
    "        \n",
    "    def __call__(self, sensor_index):\n",
    "        x = int((sensor_index % self.s) * (self.field_size + self.dist_between_sensors))\n",
    "        y = int((sensor_index // self.s) * (self.field_size + self.dist_between_sensors))\n",
    "        # adjust to fit into boundaries\n",
    "        x -= max(0, (x + self.field_size) - config.sample_size) \n",
    "        y -= max(0, (y + self.field_size) - config.sample_size)\n",
    "        return x, y, self.field_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82fd8b-3f37-4c61-96af-613d39a6cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_LAYOUT_MAKER = None\n",
    "    \n",
    "match config.retina_layout:\n",
    "    case 'grid': \n",
    "        SENSOR_LAYOUT_MAKER = SensorLayoutMaker_Grid()\n",
    "    case _:\n",
    "        assert False, config.retina_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd7b82-eb8b-46ab-8406-d0b0dad53cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not SENSOR_LAYOUT_MAKER is None\n",
    "SENSOR_INSTANCES_INFO = pd.DataFrame(columns=['x_offset', 'y_offset', 'size', 'bounds_rect', 'x_center', 'y_center', 'radius'])\n",
    "\n",
    "for i in range(SENSORS_COUNT):\n",
    "    x_offset, y_offset, field_size = SENSOR_LAYOUT_MAKER(i)\n",
    "    assert x_offset >= 0 and x_offset <= config.sample_size - field_size, (i, x_offset, field_size)\n",
    "    assert y_offset >= 0 and y_offset <= config.sample_size - field_size, (i, y_offset, field_size)\n",
    "    SENSOR_INSTANCES_INFO.loc[len(SENSOR_INSTANCES_INFO)] = [\n",
    "        x_offset,\n",
    "        y_offset,\n",
    "        field_size,\n",
    "        [x_offset, y_offset, x_offset + field_size - 1, y_offset + field_size - 1],\n",
    "        x_offset + field_size // 2,\n",
    "        y_offset + field_size // 2,\n",
    "        field_size // 2\n",
    "    ]\n",
    "\n",
    "# SENSOR_INSTANCES_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09353c08-2463-4158-ac8e-54bbe3a3bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_PATCH_COORDS = []\n",
    "    \n",
    "for row in SENSOR_INSTANCES_INFO.itertuples():\n",
    "    x_offset = row.x_offset\n",
    "    y_offset = row.y_offset\n",
    "    size = row.size\n",
    "\n",
    "    for i in range(size):\n",
    "        y = (y_offset + i) * config.sample_size\n",
    "        stride_coords = np.arange(y + x_offset, y + x_offset + size)\n",
    "        SENSOR_PATCH_COORDS.append(stride_coords)\n",
    "\n",
    "SENSOR_PATCH_COORDS = np.array(SENSOR_PATCH_COORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e125b8-dc84-416b-9232-9324574bcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_patches_for_sensor_instances(images_matrix):\n",
    "    assert images_matrix.ndim == 2, images_matrix.ndim\n",
    "    assert images_matrix.shape[1] == config.sample_size ** 2, images_matrix.shape[1]\n",
    "    images_count = images_matrix.shape[0]\n",
    "    # Result is 3d-tensor: 1 dim - image, 2 dim - patch no, 3 dim - patch itself (pixels)\n",
    "    return np.take(images_matrix, SENSOR_PATCH_COORDS, axis=1).reshape(images_count, -1, SENSOR_RECEPTIVE_FIELD_SQUARE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4655cc-5952-4064-816e-08dacb6312df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns matrix of sense_vectors (one row = sense_vector for each image in images_matrix)\n",
    "# Each elem in sense_vector describes sensor state of each sensor instance (-1 if sensor instance is not activated)\n",
    "def sense_images(images_matrix):\n",
    "    BRIGHT_ILLUMINATION_ABS_LEVEL = 255 * 0.5\n",
    "    BRIGHT_ILLUMINATION_DIRST_REL_DIFF = 0.75\n",
    "    MINIMAL_ILLUMINATION_ABS_LEVEL = 255 * 0.1\n",
    "    MINIMAL_ILLUMINATION_DIFF_DB = 2 # dB\n",
    "    MINIMAL_ILLUMINATION_DIFF_RATIO = pow(10, MINIMAL_ILLUMINATION_DIFF_DB/20)\n",
    "    MINIMAL_PLUS_MINUS_DISTR_REL_DIFF = 0.9\n",
    "    MIN_COMBO_SCORE_VALUE = 1 + 1 + (MINIMAL_PLUS_MINUS_DISTR_REL_DIFF * 2) # 1 for abs illum MAC, 1 for diff abs illum mac, the last one is for +/- tallying\n",
    "    \n",
    "    assert images_matrix.ndim == 2\n",
    "    images_count = images_matrix.shape[0]\n",
    "    images_patches = get_image_patches_for_sensor_instances(images_matrix) # array of matrices: image no -> matrix with patches as row vectors\n",
    "    \n",
    "    mean_luminiscene_in_patches = images_patches.mean(axis=2) # matrix where each row = avg of luminisnece in each patch of an image\n",
    "    mean_images_patches = images_patches.reshape(-1, SENSOR_RECEPTIVE_FIELD_SQUARE).T - mean_luminiscene_in_patches.ravel()\n",
    "    mean_images_patches = mean_images_patches.T.reshape(images_count, -1, SENSOR_RECEPTIVE_FIELD_SQUARE).transpose(0, 2, 1)\n",
    "    # mean_images_patches is an array of matrices: image no -> matrix with mean-centered patches as column vectors\n",
    "\n",
    "    min_luminiscene_in_patches = images_patches.min(axis=2) # matrix where each row = minimal of luminiscence in each patch of an image\n",
    "    min_images_patches = images_patches.reshape(-1, SENSOR_RECEPTIVE_FIELD_SQUARE).T.copy()\n",
    "    assert min_images_patches.base is None # make sure we don't corrupt images_patches during next assignment\n",
    "    min_images_patches[:] = min_luminiscene_in_patches.ravel()\n",
    "    min_images_patches = min_images_patches.T.reshape(images_count, -1, SENSOR_RECEPTIVE_FIELD_SQUARE).transpose(0, 2, 1)\n",
    "    # min_images_patches is an array of matrices: image no -> matrix with patches of minimal luminiscence as column vectors\n",
    "    \n",
    "    images_patches = images_patches.transpose(0, 2, 1) # array of matrices: image no -> matrix with patches as column vectors\n",
    "    assert images_patches.shape == mean_images_patches.shape\n",
    "    assert images_patches.shape == min_images_patches.shape\n",
    "    \n",
    "    abs_illum_level_pos = (SENSOR_STATES_POS @ images_patches).transpose(0, 2, 1)\n",
    "    abs_illum_level_neg = (SENSOR_STATES_NEG @ images_patches).transpose(0, 2, 1)\n",
    "    rel_illum_level_pos = (SENSOR_STATES_POS @ xp.where(mean_images_patches > 0, +1, 0)).transpose(0, 2, 1) # for +/- tally\n",
    "    rel_illum_level_neg = (SENSOR_STATES_NEG @ xp.where(mean_images_patches < 0, -1, 0)).transpose(0, 2, 1)  # for +/- tally\n",
    "    min_illum_level_pos = (SENSOR_STATES_POS @ min_images_patches).transpose(0, 2, 1)\n",
    "    \n",
    "    assert abs_illum_level_pos.shape == (images_count, SENSORS_COUNT, SENSOR_STATES_COUNT), abs_illum_level_pos.shape\n",
    "    assert abs_illum_level_neg.shape == abs_illum_level_pos.shape\n",
    "    assert rel_illum_level_pos.shape == abs_illum_level_pos.shape\n",
    "    assert rel_illum_level_neg.shape == abs_illum_level_pos.shape\n",
    "    assert min_illum_level_pos.shape == abs_illum_level_pos.shape\n",
    "    \n",
    "    sense_vectors = []\n",
    "    # For each patch in image we detect likelihood of activation of sensor in one of its (sensor's) state.\n",
    "    # If we have some state (say some angle and some sweep), what is condition that given patch corresponds to this state?\n",
    "    # Of course patch must be somewhat illuminated (regulated by SENSORS_POS) - this is to ensure that we don't get fooled by situation\n",
    "    # when e.g. negative part is not illuminated (dot prod is 0) while positive part is illuminated very, very week (say dot prod is 5). Looks\n",
    "    # like this is the reason why we don't hear very low frequencies or don't percieve low light - becase ratio get oversaturaed very quickly.\n",
    "    # But the key point is that sum of pixels luminiscence can meet averaged criterion only when bright pixels are concentared in area covered by SENSORS_POS\n",
    "    # and dark pixels are concentrated in area covered by SENSORS_NEG. Otherwise there will disbalance.\n",
    "    # To detect this condition we can look at distribution of mean-centered patches: +pixels must reside in positive part, -pixels must reside in negative part.\n",
    "    # To restassure that +/- distribution of pixels actually corresponds to detectable diff in illumination we also need to compare\n",
    "    # absolute illumination on positive and negative part\n",
    "    for ailp_i, ailn_i, rilp_i, riln_i, milp_i in zip(abs_illum_level_pos, abs_illum_level_neg, rel_illum_level_pos, rel_illum_level_neg, min_illum_level_pos): # Per image cycle\n",
    "        # Here and later on \"patches count\" 1-1 correspond to \"sensor instances count\" (for each sensor instance we prepare unique patch)\n",
    "        # ailp_i and ailn_i both are matrices N(patches count) x M(count of sensor states)\n",
    "        shape_save = ailp_i.shape\n",
    "\n",
    "        # UBER - must be illuminated brightly and uniformly. I.e. 1) abs illum level (sum or products of SENSOR_STATE_POS X abs illum patches) must exceed bright criteria\n",
    "        # 2) min illum level (sum of products of SENSOR_STATE_POS X min illum patches) must be close to abs illum level (this way we control minimal spread in illumination)\n",
    "        bright_abs_illumination_scores = ailp_i > BRIGHT_ILLUMINATION_ABS_LEVEL * SENSOR_STATE_AREAS_POS\n",
    "        uniform_illumination_scores = (milp_i / (ailp_i + 1e-6)) > BRIGHT_ILLUMINATION_DIRST_REL_DIFF\n",
    "    \n",
    "        # MAC {0, 1}\n",
    "        # Illumination level on positive area must exceed lower threshold (sensor must be somewhat illuminated)\n",
    "        # abs_illumination_scores = matrix of N(patches count), columns - 0/1 if patch is minimally illuminated according to given sensor's state\n",
    "        abs_illumination_scores = ailp_i > MINIMAL_ILLUMINATION_ABS_LEVEL * SENSOR_STATE_AREAS_POS\n",
    "    \n",
    "        # MAC {0, 1}\n",
    "        # Illumination level on positive part must distinguishably exceed illumination level of negative part\n",
    "        ailn_i += 1e-6 # to get rid of possible division by zero errors\n",
    "        ailp_i = ailp_i / SENSOR_STATE_AREAS_POS\n",
    "        ailn_i = ailn_i / SENSOR_STATE_AREAS_NEG\n",
    "        diff_abs_illumination_scores = xp.abs(ailp_i.ravel() / ailn_i.ravel())\n",
    "        diff_abs_illumination_scores = diff_abs_illumination_scores >= MINIMAL_ILLUMINATION_DIFF_RATIO\n",
    "        # diff_abs_illumination_scores = matrix of N(patches count), columns - 0/1 if patch is illuminated more on positive part than on negative\n",
    "        diff_abs_illumination_scores = diff_abs_illumination_scores.reshape(shape_save)\n",
    "    \n",
    "        # Score {0, [MINIMAL_PLUS_MINUS_DISTR_REL_DIFF...1]}\n",
    "        # Tally concentration of +/- pixels on positive/negative side and compare against theirs areas. \n",
    "        # For sensors with proper distribution ratio will be around 1 for each of the scores.\n",
    "        # *concentration_scores = matrix of N(patches count), columns - [0...1] how well pixels in patch are distributed according to given sensor's state\n",
    "        pluses_concentration_scores = rilp_i / SENSOR_STATE_AREAS_POS\n",
    "        # assert xp.all((pluses_concentration_scores >= 0) & (pluses_concentration_scores <= 1)) # comment for production (to speed up)\n",
    "        mask = (pluses_concentration_scores < MINIMAL_PLUS_MINUS_DISTR_REL_DIFF)\n",
    "        pluses_concentration_scores = xp.where(mask, 0, pluses_concentration_scores)\n",
    "    \n",
    "        minuses_concentration_scores = riln_i / SENSOR_STATE_AREAS_NEG\n",
    "        # assert xp.all((minuses_concentration_scores >= 0) & (minuses_concentration_scores <= 1)) # comment for production (to speed up)\n",
    "        mask = (minuses_concentration_scores < MINIMAL_PLUS_MINUS_DISTR_REL_DIFF)\n",
    "        minuses_concentration_scores = xp.where(mask, 0, minuses_concentration_scores)\n",
    "\n",
    "        # sense_vector_uber = vector of N(patches count), each value - logical sum of UBER MACs for first sensor state \n",
    "        sense_vector_uber = bright_abs_illumination_scores[:,0] & uniform_illumination_scores[:,0]\n",
    "        sense_vector_uber = xp.where(sense_vector_uber, 0, -1) # True -> 0 (UBER sensor state), False -> -1\n",
    "        \n",
    "        # sense_matrix = matrix of N(patches count), columns - sum of MACs and scores for given sensor state\n",
    "        sense_matrix = (abs_illumination_scores.astype(float) + diff_abs_illumination_scores.astype(float) + pluses_concentration_scores + minuses_concentration_scores)\n",
    "        # take all columns except the first one. First column is an UBER sensor state intended for detection of completely illuminated patch. \n",
    "        # UBER sensor state is evaluated if other sensor states didn't respond.\n",
    "        sense_submatrix = sense_matrix[:,1:] \n",
    "        sense_vector = xp.where(xp.any(sense_submatrix > MIN_COMBO_SCORE_VALUE, axis=1), 1 + xp.argmax(sense_submatrix, axis=1), -1)\n",
    "        sense_vector = xp.where(sense_vector == -1, sense_vector_uber, sense_vector)\n",
    "        sense_vectors.append(sense_vector)\n",
    "    \n",
    "    return xp.vstack(sense_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51587889-5978-49a4-8cde-0bd04c81fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# namedtuple for data export\n",
    "SensorInstance = namedtuple('SensorInstance', ['Index', 'x', 'y', 'normal', 'normal_vec', 'sweep', 'sweep_vec', 'sweep1_vec', 'sweep2_vec', 'x2', 'y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64a4bd-c8d8-4315-bfb4-833c5ac7ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SequencingContext = namedtuple('SequencingContext', \n",
    "                               ['altitude_map_hires', \n",
    "                                'altitude_lores_to_hires_translate_factor', \n",
    "                                'si_list', \n",
    "                                'outer_grooves', \n",
    "                                'outer_si_ind_dict',\n",
    "                                'inner_grooves',\n",
    "                                'inner_si_ind_dict',\n",
    "                                'outer_raw_sequences',\n",
    "                                'inner_raw_sequences', \n",
    "                                'outer_sequences',\n",
    "                                'inner_sequences'],\n",
    "                              defaults = [None] * 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e7c0d-54c0-4d9e-920c-0b4dc6047ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTITUDE_INNER = 3 #  value to designate inner interior of any figure\n",
    "\n",
    "# Returns (si_list, altitude_map) for sense_vector\n",
    "def parse_sense_vector(sense_vector):\n",
    "    ALTITUDE_EXTEND_BY = 5 # number of new intermediate cells for each side of 2x2 rect, e.g. 3x3 becomes 13x13 if altitude_extend_by is 5\n",
    "\n",
    "    assert sense_vector.shape[0] == len(SENSOR_INSTANCES_INFO)\n",
    "    sensor_instance_inds = np.argwhere(sense_vector != -1).ravel()\n",
    "    sensor_state_inds = np.take(sense_vector, sensor_instance_inds)\n",
    "    assert sensor_instance_inds.shape[0] == sensor_state_inds.shape[0]\n",
    "    df_sensor_instances_uberraw = pd.DataFrame({'sensor_instance_ind': sensor_instance_inds, 'sensor_state_ind': sensor_state_inds})\n",
    "    df_sensor_instances_uberraw = df_sensor_instances_uberraw.merge(SENSOR_STATES_INFO, how='left', left_on='sensor_state_ind', right_index=True)\n",
    "    df_sensor_instances_uberraw = df_sensor_instances_uberraw.merge(SENSOR_INSTANCES_INFO, how='left', left_on='sensor_instance_ind', right_index=True)\n",
    "    df_sensor_instances_uberraw.rename({'x_center': 'x', 'y_center': 'y'}, axis=1, inplace=True, errors='raise')\n",
    "    df_sensor_instances_uberraw[['x2', 'y2']] = df_sensor_instances_uberraw[['x', 'y']]\n",
    "    df_sensor_instances_raw = df_sensor_instances_uberraw.loc[df_sensor_instances_uberraw.sensor_state_ind != 0].copy()\n",
    "    df_sensor_instances_raw.drop(['sensor_instance_ind', 'sensor_state_ind', 'bounds_rect', 'sweep_vec', 'sweep1_vec', 'sweep2_vec', 'radius'], axis=1, inplace=True)\n",
    "    si_list_uberraw = list(df_sensor_instances_uberraw.itertuples())\n",
    "    si_list_raw = list(df_sensor_instances_raw.itertuples())\n",
    "\n",
    "    # Lo-resolution altitude map\n",
    "    altitude_map_lores = np.zeros((config.sample_size, config.sample_size))\n",
    "\n",
    "    for si in si_list_uberraw:\n",
    "        sensor_state = SENSOR_STATES[si.sensor_state_ind]\n",
    "        size = si.size\n",
    "        altitude_map_lores[si.y_offset:si.y_offset + size, si.x_offset:si.x_offset + size] += sensor_state.reshape(size, size)\n",
    "    \n",
    "    min_altitude = np.min(altitude_map_lores)\n",
    "    altitude_map_si_abscence_mask = np.full_like(altitude_map_lores, min_altitude, dtype='i')\n",
    "    \n",
    "    for si in si_list_uberraw:\n",
    "        altitude_map_si_abscence_mask[si.y_offset:si.y_offset + size, si.x_offset:si.x_offset + size] = 0\n",
    "    \n",
    "    altitude_map_lores += altitude_map_si_abscence_mask\n",
    "    altitude_map_lores = altitude_map_lores.astype('i')\n",
    "\n",
    "    # Enhance lo-resolution altitude map by interpolating. This is to develop low altitude areas which are \n",
    "    # hidden beyond patches like [[-4, -5], [3, 4]]\n",
    "    altitude_lores_to_hires_translate_factor = (ALTITUDE_EXTEND_BY + 1)\n",
    "    altitude_map_hires_size = (config.sample_size - 1) * altitude_lores_to_hires_translate_factor + 1\n",
    "    altitude_map_hires = np.zeros((altitude_map_hires_size, altitude_map_hires_size), dtype='f')\n",
    "    patch_hires_shape = (2 + ALTITUDE_EXTEND_BY, 2 + ALTITUDE_EXTEND_BY)\n",
    "    ii, jj = np.mgrid[0:patch_hires_shape[0], 0:patch_hires_shape[1]]\n",
    "    patch_hires_indices = np.array(list(zip(ii.ravel(), jj.ravel())))\n",
    "    \n",
    "    for i in range(altitude_map_lores.shape[0] - 1):\n",
    "        for j in range(altitude_map_lores.shape[1] - 1):\n",
    "            patch = altitude_map_lores[i:i+2, j:j+2].astype(float)\n",
    "    \n",
    "            if patch[0,0] == patch[0,1] and patch[0,1] == patch[1,0] and patch[1,0] == patch[1,1]:\n",
    "                patch_hires = patch[0,0]\n",
    "            else:\n",
    "                interp = RegularGridInterpolator(([0, patch_hires_shape[0] - 1], [0, patch_hires_shape[1] - 1]), patch)\n",
    "                patch_hires = interp(patch_hires_indices).reshape(patch_hires_shape)\n",
    "                \n",
    "            i_hires = i * altitude_lores_to_hires_translate_factor\n",
    "            j_hires = j * altitude_lores_to_hires_translate_factor\n",
    "            altitude_map_hires[i_hires:i_hires+patch_hires_shape[0], j_hires:j_hires+patch_hires_shape[1]] = patch_hires\n",
    "    \n",
    "    altitude_map_hires = altitude_map_hires.astype('i')\n",
    "    altitude_map_hires[altitude_map_hires > ALTITUDE_INNER - 1] = ALTITUDE_INNER\n",
    "\n",
    "    # Reposition sensor instances so they occur on a groove which surrounds outer\n",
    "    # contour of image parts. Some of the sensor instances will get discarded\n",
    "    si_list = []\n",
    "    xy_unique = set()\n",
    "    \n",
    "    for si in si_list_raw:\n",
    "        x = int(si.x * altitude_lores_to_hires_translate_factor)\n",
    "        y = int(si.y * altitude_lores_to_hires_translate_factor)\n",
    "        altitude = altitude_map_hires[y, x]\n",
    "        is_top_altitude_reached = False\n",
    "        travel_point = complex(x, y)\n",
    "    \n",
    "        for _ in range(100): # fail fast on too many iterations (shouldn't happen often)\n",
    "            x = int(travel_point.real)\n",
    "            y = int(travel_point.imag)\n",
    "    \n",
    "            if x >= 0 and x < altitude_map_hires.shape[1] and y >= 0 and y < altitude_map_hires.shape[0]:\n",
    "                if altitude_map_hires[y, x] >= ALTITUDE_INNER:\n",
    "                    is_top_altitude_reached = True\n",
    "                    break\n",
    "            else:\n",
    "                # we've hit image boundaries, ignore this si (alternative implementation may be possible though)\n",
    "                break\n",
    "                \n",
    "            travel_point -= si.normal_vec # crawl in direction opposite to normal\n",
    "    \n",
    "        if not is_top_altitude_reached:\n",
    "            continue\n",
    "    \n",
    "        is_cliff_reached = False\n",
    "            \n",
    "        for _ in range(100):\n",
    "            x = int(travel_point.real)\n",
    "            y = int(travel_point.imag)\n",
    "    \n",
    "            if x >= 0 and x < altitude_map_hires.shape[1] and y >= 0 and y < altitude_map_hires.shape[0]:\n",
    "                if altitude_map_hires[y, x] < ALTITUDE_INNER:\n",
    "                    # This si falled out of cliff\n",
    "                    break\n",
    "            \n",
    "            for rel_xy in itertools.product(range(-1, 1 + 1), repeat=2):\n",
    "                test_x = x + rel_xy[0]\n",
    "                test_y = y + rel_xy[1]\n",
    "        \n",
    "                if test_x < 0 or test_y < 0 or test_x >= altitude_map_hires.shape[1] or test_y >= altitude_map_hires.shape[0]:\n",
    "                    continue\n",
    "                elif altitude_map_hires[test_y, test_x] >= ALTITUDE_INNER:\n",
    "                    continue\n",
    "                \n",
    "                is_cliff_reached = True\n",
    "                break\n",
    "            else:\n",
    "                travel_point += si.normal_vec\n",
    "    \n",
    "            if is_cliff_reached:\n",
    "                break\n",
    "                        \n",
    "        if is_cliff_reached:\n",
    "            if not (x, y) in xy_unique:\n",
    "                # Make sure NO xy lays on the edge of altitude map boundaries (otherwise we will face with constant checks and code will be complicated/slowdown)\n",
    "                assert x > 0 and x < altitude_map_hires.shape[1] - 1\n",
    "                assert y > 0 and y < altitude_map_hires.shape[0] - 1\n",
    "                x_lores = round(x / altitude_lores_to_hires_translate_factor)\n",
    "                y_lores = round(y / altitude_lores_to_hires_translate_factor)\n",
    "                si_list.append(si._replace(x2=x, y2=y, x=x_lores, y=y_lores))\n",
    "                xy_unique.add((x, y))\n",
    "\n",
    "    return SequencingContext(si_list=si_list, altitude_map_hires=altitude_map_hires, altitude_lores_to_hires_translate_factor=altitude_lores_to_hires_translate_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef6abf-867f-4b15-ae23-a56444f92283",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAREST_NEIGHB_REL_XY_LIST = list(itertools.product(range(-1, 1 + 1), repeat=2))\n",
    "NEAREST_NEIGHB_REL_XY_LIST.remove((0, 0))\n",
    "NEAREST_NEIGHB_REL_XY_LIST = np.array(NEAREST_NEIGHB_REL_XY_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484b438-4edf-4096-8cb5-dd1688088a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outer_grooves(seq_context):\n",
    "    wave_fronts = deque()\n",
    "    xy_touched = set()\n",
    "    \n",
    "    for si_ind, si in enumerate(seq_context.si_list):\n",
    "        x, y = (si.x2, si.y2)\n",
    "        assert not (x, y) in xy_touched\n",
    "        xy_touched.add((x, y))\n",
    "        wave_fronts.append((x, y, si_ind))\n",
    "        \n",
    "    outer_grooves_map = np.full_like(seq_context.altitude_map_hires, -1, dtype='i')\n",
    "    \n",
    "    while wave_fronts:\n",
    "        x, y, si_ind = wave_fronts.popleft()\n",
    "        assert outer_grooves_map[y, x] == -1, outer_grooves_map[y, x]\n",
    "    \n",
    "        # point at x,y must be on cliff - i.e. one of its neighbours must be out of plateau (altitude=3)\n",
    "        for rel_xy in NEAREST_NEIGHB_REL_XY_LIST:\n",
    "            test_x = x + rel_xy[0]\n",
    "            test_y = y + rel_xy[1]\n",
    "    \n",
    "            if seq_context.altitude_map_hires[test_y, test_x] < ALTITUDE_INNER:\n",
    "                # cliff condition met\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        outer_grooves_map[y, x] = si_ind\n",
    "    \n",
    "        for rel_xy in NEAREST_NEIGHB_REL_XY_LIST:\n",
    "            test_x = x + rel_xy[0]\n",
    "            test_y = y + rel_xy[1]\n",
    "    \n",
    "            if seq_context.altitude_map_hires[test_y, test_x] < ALTITUDE_INNER:\n",
    "                continue\n",
    "            elif outer_grooves_map[test_y, test_x] != -1:\n",
    "                continue\n",
    "            elif (test_x, test_y) in xy_touched:\n",
    "                continue\n",
    "    \n",
    "            wave_fronts.append((test_x, test_y, si_ind))\n",
    "            xy_touched.add((test_x, test_y))\n",
    "    \n",
    "    outer_grooves = []\n",
    "    \n",
    "    for ij in np.argwhere(outer_grooves_map != -1):\n",
    "        x, y = int(ij[1]), int(ij[0])\n",
    "        si_ind = outer_grooves_map[y, x]\n",
    "        outer_grooves.append((x, y, si_ind))\n",
    "    \n",
    "    outer_grooves = np.array(outer_grooves)\n",
    "    outer_si_ind_dict = dict(map(lambda si_ind_si: (si_ind_si[0], si_ind_si[1]), enumerate(seq_context.si_list)))\n",
    "    \n",
    "    return seq_context._replace(outer_grooves=outer_grooves, outer_si_ind_dict=outer_si_ind_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126dc28f-a920-4b2a-b57d-cf589dc2cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_grooves(seq_context):\n",
    "    wave_fronts = deque()\n",
    "    xy_touched = set()\n",
    "    \n",
    "    for x, y, si_ind in seq_context.outer_grooves:\n",
    "        xy_touched.add((x, y))\n",
    "        wave_fronts.append((x, y, si_ind))\n",
    "    \n",
    "    inner_grooves_map = np.full_like(seq_context.altitude_map_hires, -1, dtype='i')\n",
    "    inner_grooves = []\n",
    "    inner_groove_bits = []\n",
    "    rel_xy_list = NEAREST_NEIGHB_REL_XY_LIST.copy()\n",
    "    \n",
    "    while wave_fronts:\n",
    "        x, y, si_ind = wave_fronts.popleft()\n",
    "        assert inner_grooves_map[y, x] == -1, inner_grooves_map[y, x]\n",
    "        inner_grooves_map[y, x] = si_ind\n",
    "        is_amberified = True\n",
    "    \n",
    "        RNG.shuffle(rel_xy_list)\n",
    "        \n",
    "        for rel_xy in rel_xy_list:\n",
    "            test_x = x + rel_xy[0]\n",
    "            test_y = y + rel_xy[1]\n",
    "    \n",
    "            # if test_x < 0 or test_y < 0 or test_x >= seq_context.altitude_map_hires.shape[1] or test_y >= seq_context.altitude_map_hires.shape[0]:\n",
    "            #     continue\n",
    "            # elif \n",
    "            if seq_context.altitude_map_hires[test_y, test_x] < ALTITUDE_INNER:\n",
    "                continue\n",
    "            elif inner_grooves_map[test_y, test_x] != -1:\n",
    "                continue\n",
    "            elif (test_x, test_y) in xy_touched:\n",
    "                continue\n",
    "    \n",
    "            wave_fronts.append((test_x, test_y, si_ind))\n",
    "            xy_touched.add((test_x, test_y))\n",
    "            is_amberified = False\n",
    "    \n",
    "        if is_amberified:\n",
    "            inner_groove_bits.append((x, y))\n",
    "            si_ind_normal_vec = seq_context.si_list[si_ind].normal_vec\n",
    "            \n",
    "            for rel_xy in NEAREST_NEIGHB_REL_XY_LIST:\n",
    "                test_x = x + rel_xy[0]\n",
    "                test_y = y + rel_xy[1]\n",
    "        \n",
    "                # if test_x < 0 or test_y < 0 or test_x >= inner_grooves_map.shape[1] or test_y >= inner_grooves_map.shape[0]:\n",
    "                #     continue\n",
    "                # elif \n",
    "                if inner_grooves_map[test_y, test_x] == -1:\n",
    "                    continue\n",
    "                \n",
    "                other_si_ind = inner_grooves_map[test_y, test_x]\n",
    "    \n",
    "                if si_ind == other_si_ind:\n",
    "                    continue\n",
    "                    \n",
    "                other_si_ind_normal_vec = seq_context.si_list[other_si_ind].normal_vec\n",
    "                dot_prod = si_ind_normal_vec.real * other_si_ind_normal_vec.real + si_ind_normal_vec.imag * other_si_ind_normal_vec.imag\n",
    "    \n",
    "                if dot_prod < 0: \n",
    "                    inner_grooves.append((x, y, si_ind))\n",
    "                    break\n",
    "    \n",
    "    inner_grooves = np.array(inner_grooves)\n",
    "    inner_si_ind_dict = {}\n",
    "    \n",
    "    for i in range(inner_grooves.shape[0]):\n",
    "        x, y, si_ind = inner_grooves[i]\n",
    "        si = seq_context.si_list[si_ind]\n",
    "        x_lores = round(x / seq_context.altitude_lores_to_hires_translate_factor)\n",
    "        y_lores = round(y / seq_context.altitude_lores_to_hires_translate_factor)\n",
    "        new_si_ind_value = len(inner_si_ind_dict)\n",
    "        inner_si_ind_dict[new_si_ind_value] = si._replace(x2=int(x), y2=int(y), x=x_lores, y=y_lores)\n",
    "        inner_grooves[i, 2] = new_si_ind_value\n",
    "    \n",
    "    return seq_context._replace(inner_grooves=inner_grooves, inner_si_ind_dict=inner_si_ind_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6369ab-84d0-46f7-bb33-a71acfcf3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROOVE_ENDPOINT_TEMPLATE = np.array([[1, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "GROOVE_ENDPOINT_TEMPLATES = []\n",
    "\n",
    "for t in [GROOVE_ENDPOINT_TEMPLATE, np.fliplr(GROOVE_ENDPOINT_TEMPLATE)]:\n",
    "    GROOVE_ENDPOINT_TEMPLATES.append(t)\n",
    "    GROOVE_ENDPOINT_TEMPLATES.append(np.rot90(t))\n",
    "    GROOVE_ENDPOINT_TEMPLATES.append(np.rot90(np.rot90(t)))\n",
    "    GROOVE_ENDPOINT_TEMPLATES.append(np.rot90(np.rot90(np.rot90(t))))\n",
    "\n",
    "GROOVE_ENDPOINT_TEMPLATES = np.array(GROOVE_ENDPOINT_TEMPLATES)\n",
    "\n",
    "def get_outer_starting_si_inds(grooves, grooves_map):\n",
    "    # outer si_inds corresponds to a circular contour, \n",
    "    # so we can start anywhere (i.e. from any si)\n",
    "    return set(grooves[:,2])\n",
    "\n",
    "def get_inner_starting_si_inds(grooves, grooves_map):\n",
    "    r = set()\n",
    "    \n",
    "    for x, y, si_ind in grooves:\n",
    "        assert x > 0\n",
    "        assert y > 0\n",
    "        assert x < grooves_map.shape[1] - 1\n",
    "        assert y < grooves_map.shape[0] - 1\n",
    "        patch = grooves_map[y-1:y+2, x-1:x+2]\n",
    "        s = (GROOVE_ENDPOINT_TEMPLATES * patch).reshape(GROOVE_ENDPOINT_TEMPLATES.shape[0], -1).sum(axis=-1)\n",
    "        \n",
    "        if np.any(s == -6):\n",
    "            r.add(si_ind)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c3e8c-ac06-411c-bfdd-f8a3c3433fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _populate_raw_sequences(raw_sequences, seq_context, grooves, si_ind_dict, get_starting_si_inds):\n",
    "    grooves_map = np.full_like(seq_context.altitude_map_hires, -1, dtype='i')\n",
    "\n",
    "    for x, y, si_ind in grooves:\n",
    "        grooves_map[y, x] = si_ind\n",
    "    \n",
    "    xy_on_grooves_to_si_ind = dict(map(lambda item: ((item[1].x2, item[1].y2), item[0]), si_ind_dict.items()))  # xy -> si_ind. Deduplication by xy happens here\n",
    "    starting_si_inds = get_starting_si_inds(grooves, grooves_map)\n",
    "    \n",
    "    while starting_si_inds:\n",
    "        # choose random sensor instance to start from\n",
    "        start_sensor_inst_index = starting_si_inds.pop()\n",
    "        si = si_ind_dict[start_sensor_inst_index]\n",
    "        si_xy = (si.x2, si.y2)\n",
    "        si_ij = int(si_xy[1]), int(si_xy[0])\n",
    "        \n",
    "        wave_front_que = deque([si_ij])\n",
    "        wave_front_map = np.full_like(seq_context.altitude_map_hires, -1, dtype='i')\n",
    "        wave_front_map[wave_front_que[0]] = start_sensor_inst_index\n",
    "        wave_front_touched = set([wave_front_que[0]])\n",
    "        \n",
    "        sensor_inst_chains = {} # key - last element in chain of sensor instances, value - chain itself\n",
    "        \n",
    "        # LOG(f'Starting walk from {start_sensor_inst_index} (of {len(starting_si_inds)})')\n",
    "        \n",
    "        while wave_front_que:\n",
    "            # Visit point on top of the wave_front\n",
    "            wave_front_point = wave_front_que.popleft()\n",
    "            wave_front_sensor_inst_ind = int(wave_front_map[wave_front_point])\n",
    "            wave_front_sensor_inst_ind1 = wave_front_sensor_inst_ind\n",
    "            wave_front_map[wave_front_point] = -1\n",
    "            assert wave_front_sensor_inst_ind > -1\n",
    "            # LOG(f'Visiting {wave_front_point} (si={wave_front_sensor_inst_ind}) (of {len(wave_front_que)})')\n",
    "        \n",
    "            si_ind = xy_on_grooves_to_si_ind.get((wave_front_point[1], wave_front_point[0]), -1)\n",
    "        \n",
    "            if si_ind != -1 and si_ind != wave_front_sensor_inst_ind:\n",
    "                # New sensor instance discovered! Link with the previous one, ...\n",
    "                sensor_inst_chain = sensor_inst_chains.pop(wave_front_sensor_inst_ind, [wave_front_sensor_inst_ind])\n",
    "                sensor_inst_chain.append(si_ind)\n",
    "                assert not si_ind in sensor_inst_chains, f'{si_ind} in sensor_inst_chains'\n",
    "                sensor_inst_chains[si_ind] = sensor_inst_chain\n",
    "                \n",
    "                # LOG(f'New si encountered: {si_ind}, linked after {wave_front_sensor_inst_ind}')\n",
    "                wave_front_sensor_inst_ind = si_ind\n",
    "                # ... and adjust adjacent wave front points to account for new sensor instance\n",
    "                # (adjacency criteria enables coexisting of separate (disjoint) wave fronts on a map)\n",
    "                adjust_stack = [wave_front_point]\n",
    "                adjust_touched = set([wave_front_point])\n",
    "        \n",
    "                while adjust_stack:\n",
    "                    adjust_point = adjust_stack.pop()\n",
    "        \n",
    "                    for rel_ij in [[0, -1], [-1, 0], [0, 1], [1, 0], [-1, -1], [-1, 1], [1, 1], [1, -1]]:\n",
    "                        ij = int(adjust_point[0] + rel_ij[0]), int(adjust_point[1] + rel_ij[1])\n",
    "                \n",
    "                        if wave_front_map[ij] == -1:\n",
    "                            continue\n",
    "                        elif ij in adjust_touched:\n",
    "                            continue\n",
    "        \n",
    "                        # LOG(f'Adjusting {ij} (si={wave_front_map[ij]}) to si={si_ind}')\n",
    "                        wave_front_map[ij] = si_ind\n",
    "                        adjust_stack.append(ij)\n",
    "                        adjust_touched.add(ij)\n",
    "        \n",
    "            # Plan further spread of the wave front\n",
    "            for rel_ij in [[0, -1], [-1, 0], [0, 1], [1, 0], [-1, -1], [-1, 1], [1, 1], [1, -1]]:\n",
    "                ij = int(wave_front_point[0] + rel_ij[0]), int(wave_front_point[1] + rel_ij[1])\n",
    "                # LOG(f'... spread, checking coord {rel_ij} {ij}')\n",
    "        \n",
    "                if grooves_map[ij] == -1:  # coord_ij falls out of groove\n",
    "                    # LOG(f'... spread, {ij} is out of groove')\n",
    "                    continue\n",
    "                elif ij in wave_front_touched:\n",
    "                    # LOG(f'... spread, {ij} already touched ({len(wave_front_touched)})')\n",
    "                    continue\n",
    "        \n",
    "                wave_front_touched.add(ij)\n",
    "                wave_front_que.append(ij)\n",
    "                wave_front_map[ij] = wave_front_sensor_inst_ind\n",
    "                # LOG(f'... new wave front point {wave_front_que[-1]} (si={wave_front_sensor_inst_ind})')\n",
    "\n",
    "        if sensor_inst_chains:\n",
    "            raw_sequences[start_sensor_inst_index] = sensor_inst_chains\n",
    "            \n",
    "        # Collect all sensor instances encountered during this run and mark them as processed\n",
    "        processed_sensor_instance_inds = set(itertools.chain.from_iterable(sensor_inst_chains.values()))\n",
    "        starting_si_inds -= processed_sensor_instance_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb98af-7402-4143-897f-28e2a5c083fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outer_raw_sequences(seq_context):\n",
    "    outer_raw_sequences = {}\n",
    "    _populate_raw_sequences(outer_raw_sequences, seq_context, seq_context.outer_grooves, seq_context.outer_si_ind_dict, get_outer_starting_si_inds)\n",
    "    return seq_context._replace(outer_raw_sequences=outer_raw_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2952d-58d5-4f83-aa31-fdf012f6ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outer_sequences(seq_context):\n",
    "    outer_sequences = []\n",
    "        \n",
    "    for sensor_inst_chains in seq_context.outer_raw_sequences.values():\n",
    "        # Our goal is to find two longest subsequence which start from the same si and clue them together. \n",
    "        # Usually this would be two subsequences starting from start_sensor_inst_index.\n",
    "        # This way we would get longest serial sequence of traverse\n",
    "        subsequences = []\n",
    "        \n",
    "        for chain_index, chain in enumerate(sensor_inst_chains.values()):\n",
    "            # get all chains OTHER THAN current chain under chain_index\n",
    "            chains_wo_chain_index = map(lambda v: v[1], filter(lambda v: v[0] != chain_index, enumerate(sensor_inst_chains.values())))\n",
    "            chains_dict = defaultdict(list)\n",
    "            for v in chains_wo_chain_index: chains_dict[v[0]].append(v)\n",
    "            \n",
    "            subsequences.append([])\n",
    "            branch_stack = [(chain, 0, len(subsequences) - 1)]\n",
    "            LOG(f'Starting new subsequence #{len(subsequences) - 1}, {chain[0]}')\n",
    "        \n",
    "            while branch_stack:\n",
    "                chain, chain_elem_index, subseq_index = branch_stack.pop()\n",
    "                subseq = subsequences[subseq_index]\n",
    "                LOG(f'Weaving subsequence #{subseq_index}, {chain[chain_elem_index]}')\n",
    "                \n",
    "                for i in range(chain_elem_index, len(chain)):\n",
    "                    v = chain[i]\n",
    "                    subseq.append(v)\n",
    "                    LOG(f'... adding {chain[i]}, subseq len={len(subseq)}, subseq[:3]={subseq[:3]}, subseq[-3:]={subseq[-3:]}')\n",
    "        \n",
    "                    if v in chains_dict:\n",
    "                        LOG(f'... branch point detected')\n",
    "                        # New branch point detected\n",
    "                        branch_stack.append((chain, i + 1, subseq_index)) # continue sequence by following current chain\n",
    "    \n",
    "                        # Start new subsequences from new chain\n",
    "                        for branch_chain in chains_dict[v]:\n",
    "                            new_subseq = subseq.copy()\n",
    "                            subsequences.append(new_subseq)\n",
    "                            branch_stack.append((branch_chain, 1, len(subsequences) - 1)) # create new sequence and follow new chain\n",
    "                            LOG(f'... branching new subsequence #{len(subsequences) - 1}, {branch_chain[1]}')\n",
    "                            \n",
    "                        break\n",
    "    \n",
    "        longest_sequence = []\n",
    "    \n",
    "        if not subsequences:\n",
    "            continue\n",
    "        elif len(subsequences) == 1:\n",
    "            longest_subsequence = subsequences[0]\n",
    "        else:\n",
    "            for ii in itertools.combinations(range(len(subsequences)), 2):\n",
    "                subseq1 = subsequences[ii[0]]\n",
    "                subseq2 = subsequences[ii[1]]\n",
    "                prefix_i = 0\n",
    "        \n",
    "                while prefix_i < min(len(subseq1), len(subseq2)) and subseq1[prefix_i] == subseq2[prefix_i]:\n",
    "                    prefix_i += 1\n",
    "        \n",
    "                if prefix_i == 0:\n",
    "                    # No common prefix, cant clue these two subseqs\n",
    "                    continue\n",
    "        \n",
    "                sequence = list(reversed(subseq1[prefix_i:])) + [subseq1[prefix_i - 1]] + subseq2[prefix_i:]\n",
    "        \n",
    "                if len(sequence) > len(longest_sequence):\n",
    "                    longest_sequence = sequence\n",
    "    \n",
    "        if longest_sequence:\n",
    "            outer_sequences.append(longest_sequence)\n",
    "    \n",
    "    return seq_context._replace(outer_sequences=outer_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d85ba-6bba-4a74-81b6-3d62d5846d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_raw_sequences(seq_context):\n",
    "    inner_raw_sequences = {}\n",
    "    _populate_raw_sequences(inner_raw_sequences, seq_context, seq_context.inner_grooves, seq_context.inner_si_ind_dict, get_inner_starting_si_inds)\n",
    "    return seq_context._replace(inner_raw_sequences=inner_raw_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8eb30-70a8-44a7-852b-eb09006d7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_sequences(seq_context):\n",
    "    inner_sequences = list(itertools.chain.from_iterable(map(lambda chain_dict: chain_dict.values(), seq_context.inner_raw_sequences.values())))\n",
    "    return seq_context._replace(inner_sequences=inner_sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
